{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webScraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJVjWygkQWjxUArlKOFpzS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lromano97/text-mining/blob/main/webScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tf_xSo0SnwA"
      },
      "source": [
        "# Scraping de la página TED\n",
        "\n",
        "En ted_main de kaggle hay 2550 valores, mientras que en la página de [TED](https://www.ted.com/talks?page=142&sort=popular) hay hoy (12/mayo/21) 5092.\n",
        "\n",
        "De acuerdo a la descarga, estos son los datos con los que contamos.\n",
        "\n",
        "*   5092 charlas (5072 en inglés)\n",
        "*   4482 transcripciones (4479 en inglés)\n",
        "*   En la descarga hay varias charlas que están en otros idiomas, pero las transcripciones están en inglés\n",
        "\n",
        "Esta notebook es una adaptación de [TED-Scraper en Git Hub](https://github.com/The-Gupta/TED-Scraper)\n",
        "\n",
        "Una posible mejora a este script es buscar descargar el título, la descripción y la trascripción en español (aparentemente hay 4283)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqCiIvyY3ohY"
      },
      "source": [
        "# Preparación del entorno ----\n",
        "\n",
        "# Descarga de metadatos y transcripciones\n",
        "import time, requests, bs4, json, random\n",
        "from multiprocessing import Manager, Process\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Sin warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4q61YFDDa7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110fb4d7-7449-4b61-dadb-d50c639fed02"
      },
      "source": [
        "# Activacndo Google Drive para guardar la información\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc5fksH4ENTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b24df86-10ec-40d3-b4e0-f2d3a3c5bf2d"
      },
      "source": [
        "cd \"/content/gdrive/My Drive/Colab Notebooks/Text Mining/TopicsTED\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/Text Mining/TopicsTED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNhzyP3DKLv2"
      },
      "source": [
        "## Descarga de Metadatos y Transcripciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SrfqB3IKvq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fec8df1-ddc9-4829-e0ae-6b4f9cf20713"
      },
      "source": [
        "time__  =  time.time()     # Tiempo de corrida en Collab es de 6 minutos\n",
        "\n",
        "\n",
        "urls = []\n",
        "page_number=0\n",
        "\n",
        "while 1:\n",
        "    page_number += 1\n",
        "\n",
        "    res  =  requests.get(\"https://www.ted.com/talks?sort=popular&page=\" + str(page_number), \n",
        "                         headers = {'User-agent': 'your bot 0.1'})\n",
        "\n",
        "    soup = bs4.BeautifulSoup(res.text)\n",
        "    e = soup.select(\"div.container.results div.col\")\n",
        "    \n",
        "    if len(e) == 0:    break    # No more videos.\n",
        "    \n",
        "    for  u  in e:\n",
        "        urls.append(\"https://www.ted.com\" + u.select(\"div.media__image a.ga-link\")[0].get(\"href\"))\n",
        "\n",
        "\n",
        "# Saving.\n",
        "f = open('TED_Talk_URLs.txt', 'w')\n",
        "f.write('\\n'.join(urls))\n",
        "f.close()\n",
        "\n",
        "\n",
        "def download(urls, id_, csv_list):\n",
        "                for count, url in enumerate(urls):\n",
        "\n",
        "                        def get_transcript(url):\n",
        "                                transcript = \"\"\n",
        "                                transcript_res = requests.get(url, headers = {'User-agent': 'your bot 0.1'})\n",
        "                                \n",
        "                                soup = BeautifulSoup(transcript_res.text)\n",
        "                                e = soup.select('div.Grid.Grid--with-gutter.p-b:4')\n",
        "\n",
        "                                for  e_  in e:\n",
        "                                    classes = e_.get('class')\n",
        "                                    text = e_.select('p')[0].text\n",
        "                                    transcript += text.strip().replace('\\t', '').replace('\\n', ' ')\n",
        "                                \n",
        "                                if (transcript_res.status_code!=200) or (transcript_res.text=='') or (transcript==''):\n",
        "                                    count_=0\n",
        "                                    while  count_ < 3:    # Check 3 more times\n",
        "                                        time.sleep(random.randint(0,900)/1000)     # Randomly wait for 0-0.9 seconds.\n",
        "                                        transcript_res = requests.get(url, headers = {'User-agent': 'your bot 0.1'})\n",
        "\n",
        "                                        soup = BeautifulSoup(transcript_res.text)\n",
        "                                        e = soup.select('div.Grid.Grid--with-gutter.p-b:4')\n",
        "\n",
        "                                        for  e_  in e:\n",
        "                                            classes = e_.get('class')\n",
        "                                            text = e_.select('p')[0].text\n",
        "                                            transcript += text.strip().replace('\\t', '').replace('\\n', ' ')\n",
        "\n",
        "                                        count_ += 1\n",
        "                                        if (transcript_res.status_code==200) and (transcript_res.text!='') and (transcript!=''):    break\n",
        "\n",
        "                                return transcript\n",
        "\n",
        "\n",
        "\n",
        "                        def get__json_obj(url):\n",
        "                            res = requests.get(url.strip(), headers = {'User-agent': 'your bot 0.1'})\n",
        "                            html = res.text\n",
        "\n",
        "                            start_index  =  html.find('<script data-spec=\"q\">q(\"talkPage.init\",')\n",
        "                            end_index    =  html[start_index:].find(')</script>')\n",
        "                            script_tag   =  html[start_index: start_index + end_index]\n",
        "                            json_obj  =  script_tag[len('<script data-spec=\"q\">q(\"talkPage.init\",'):]\n",
        "                            return json_obj\n",
        "\n",
        "                        json_obj  =  get__json_obj(url)\n",
        "\n",
        "                        if not json_obj:\n",
        "                            count=0\n",
        "                            while  count < 3:    # Check 3 more times\n",
        "                                json_obj  =  get__json_obj(url)\n",
        "                                count += 1\n",
        "                                if json_obj:    break\n",
        "\n",
        "                        if not json_obj:    print(url);continue;\n",
        "                        else:               metadata = json.loads(json_obj)[\"__INITIAL_DATA__\"]\n",
        "\n",
        "\n",
        "\n",
        "                        def get_value(l, m=metadata):\n",
        "                            for i in l:\n",
        "                                try:    m = m[i]\n",
        "                                except: return ''\n",
        "                            return m\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                        def html_to_text(html):\n",
        "                            if str(html)!='nan':\n",
        "                                soup = BeautifulSoup(html)\n",
        "                                return soup.get_text()\n",
        "                            else: return html\n",
        "\n",
        "\n",
        "                        d = dict()\n",
        "\n",
        "                        # Acerca de la Charla\n",
        "                        d[\"talk__id\"]  =  get_value([\"current_talk\"], metadata)\n",
        "                        d[\"talk__name\"]  =  get_value([\"talks\", 0, \"title\"], metadata)\n",
        "                        d[\"talk__description\"]  =  get_value([\"description\"], metadata)\n",
        "                        d[\"view_count\"]  =  get_value([\"viewed_count\"], metadata)\n",
        "                        d[\"duration\"]  =  get_value([\"talks\", 0, \"duration\"], metadata)    # In seconds.\n",
        "\n",
        "                        language  =  get_value([\"language\"], metadata)\n",
        "                        url__transcript  =  url + \"/transcript?language=\" + language\n",
        "                        d[\"transcript\"]  =  get_transcript(url__transcript)\n",
        "\n",
        "                        d[\"video_type_name\"]  =  get_value([\"talks\", 0, \"video_type\", \"name\"], metadata)    # One of:  TED Stage Talk, TEDx Talk, TED-Ed Original, TED Institute Talk, Best of Web, Original Content, TED Salon Talk (partner), Custom sponsored content\n",
        "                        d[\"event\"]  =  get_value([\"event\"], metadata)\n",
        "                    \n",
        "\n",
        "                        # Acerca del conferencista\n",
        "                        d[\"speaker__id\"]  =  get_value([\"speakers\", 0, \"id\"], metadata)                        \n",
        "                        d[\"speaker__name\"]  =  get_value([\"talks\", 0, \"speaker_name\"], metadata)\n",
        "                        d[\"speaker__description\"]  =  get_value([\"speakers\", 0, \"description\"], metadata)\n",
        "                        d[\"speaker__who_he_is\"]  =  get_value([\"speakers\", 0, \"whotheyare\"], metadata)\n",
        "                        d[\"speaker__why_listen\"]  =  html_to_text(get_value([\"speakers\", 0, \"whylisten\"], metadata))\n",
        "                        d[\"all_speakers_details\"]  =  get_value([\"speakers\"], metadata)\n",
        "                        \n",
        "\n",
        "                        # Recorded and Published time.\n",
        "                        temp  =  get_value([\"talks\", 0, \"recorded_at\"], metadata)\n",
        "                        d[\"recording_date\"]  =  temp  if temp==None  else temp[:10]\n",
        "                        \n",
        "                        t  =  get_value([\"talks\", 0, \"player_talks\", 0, \"published\"], metadata)\n",
        "                        d[\"published_timestamp\"]  =  datetime.utcfromtimestamp(int(t)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "                        \n",
        "\n",
        "                        # Tags\n",
        "                        d[\"talks__tags\"]  =  get_value([\"talks\", 0, \"tags\"], metadata)\n",
        "                        d[\"number_of__tags\"]  =  len(get_value([\"talks\", 0, \"tags\"], metadata) or \"\")\n",
        "                        \n",
        "\n",
        "                        d[\"language\"]  =  language\n",
        "                        d[\"native_language\"]  =  get_value([\"talks\", 0, \"player_talks\", 0, \"nativeLanguage\"], metadata)\n",
        "\n",
        "                        \n",
        "                        # URLs.\n",
        "                        d[\"url__webpage\"]  =  get_value([\"url\"], metadata)\n",
        "                        \n",
        "\n",
        "                        # More resources.\n",
        "                        d[\"talk__more_resources\"]  =  get_value([\"talks\", 0, \"more_resources\"], metadata)\n",
        "                        d[\"number_of__talk__more_resources\"]  =  len(get_value([\"talks\", 0, \"more_resources\"], metadata) or \"\")\n",
        "\n",
        "\n",
        "                        # Recommendations.\n",
        "                        d[\"talk__recommendations__blurb\"]  =  get_value([\"talks\", 0, \"recommendations\", \"blurb\"], metadata)\n",
        "                        \n",
        "                        d[\"talk__recommendations\"]  =  get_value([\"talks\", 0, \"recommendations\", \"rec_lists\"], metadata)\n",
        "                        d[\"number_of__talk__recommendations\"]  =  len(get_value([\"talks\", 0, \"recommendations\", \"rec_lists\"], metadata) or \"\")\n",
        "\n",
        "\n",
        "                        # Related Talks.\n",
        "                        d[\"related_talks\"]  =  get_value([\"talks\", 0, \"related_talks\"], metadata)\n",
        "                        d[\"number_of__related_talks\"]  =  len(get_value([\"talks\", 0, \"related_talks\"], metadata) or \"\")\n",
        "\n",
        "\n",
        "                        csv_list.append(d)\n",
        "\n",
        "csv_list_ = []\n",
        "with  Manager()  as manager:\n",
        "    csv_list = manager.list()    # SPECIAL variable - can be used only locally\n",
        "    Processess = []\n",
        "    \n",
        "    concurreny_count  =  100\n",
        "    urls_  =  [urls[(i* (len(urls)//concurreny_count)):((i+1)* (len(urls)//concurreny_count))]    for i in range(concurreny_count)]\n",
        "    \n",
        "    leftovers  =  urls[(concurreny_count * (len(urls)//concurreny_count))  :  len(urls)]\n",
        "    for i in range(len(leftovers)):    urls_[i] += [leftovers[i]]\n",
        "    \n",
        "    for  (id_,urls__)  in enumerate(urls_):\n",
        "        p = Process(target=download, args=(urls__,id_,csv_list))\n",
        "        Processess.append(p)\n",
        "        p.start()\n",
        "        \n",
        "    # block until all the threads finish (i.e. block until all **download** function calls finish)\n",
        "    for t in Processess:    t.join()\n",
        "    \n",
        "    csv_list_ = list(csv_list)\n",
        "\n",
        "# Creating DataFrame.\n",
        "df  =  pd.DataFrame(csv_list_)\n",
        "\n",
        "# Sort - most popular first.\n",
        "df = df.sort_values(\"view_count\", ascending=False)\n",
        "\n",
        "# Saving.\n",
        "df.to_excel('TED_Talk.xlsx', encoding='utf-8', index=False)\n",
        "df.to_csv('TED_Talk.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(round(time.time()  -  time__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "337\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}